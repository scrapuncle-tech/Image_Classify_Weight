{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "814ad7d7",
   "metadata": {},
   "source": [
    "# For Red Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a09285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize EasyOCR once globally\n",
    "reader = easyocr.Reader(['en'], gpu=True)  # Set to False if no GPU\n",
    "\n",
    "class OptimizedDisplayDetector:\n",
    "    \"\"\"Optimized detector for digital displays\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_red_orange_numbers(image):\n",
    "        \"\"\"Optimized detection for red/orange numbers\"\"\"\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Simplified color ranges\n",
    "        ranges = [\n",
    "            ([0, 50, 50], [15, 255, 255]),      # Red range 1\n",
    "            ([165, 50, 50], [180, 255, 255]),   # Red range 2\n",
    "            ([10, 80, 80], [25, 255, 255]),     # Orange range\n",
    "        ]\n",
    "        \n",
    "        # Combine masks efficiently\n",
    "        combined_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "        for lower, upper in ranges:\n",
    "            mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "            combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "        \n",
    "        # Single morphological operation\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "        \n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not contours:\n",
    "            return None, None\n",
    "        \n",
    "        # Get largest contour above minimum area\n",
    "        valid_contours = [c for c in contours if cv2.contourArea(c) > 50]\n",
    "        if not valid_contours:\n",
    "            return None, None\n",
    "        \n",
    "        largest_contour = max(valid_contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        # Add padding\n",
    "        padding = max(10, min(w, h) // 4)\n",
    "        x = max(0, x - padding)\n",
    "        y = max(0, y - padding)\n",
    "        w = min(image.shape[1] - x, w + 2 * padding)\n",
    "        h = min(image.shape[0] - y, h + 2 * padding)\n",
    "        \n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        return (x, y, w, h), roi\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_bright_regions(image):\n",
    "        \"\"\"Detect bright regions that might contain displays\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Find bright regions\n",
    "        _, bright_mask = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Morphological operations\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "        bright_mask = cv2.morphologyEx(bright_mask, cv2.MORPH_CLOSE, kernel)\n",
    "        \n",
    "        contours, _ = cv2.findContours(bright_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        regions = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 200:  # Minimum area\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / h if h > 0 else 0\n",
    "                if 0.5 < aspect_ratio < 10:  # Reasonable aspect ratio\n",
    "                    regions.append((x, y, w, h))\n",
    "        \n",
    "        return regions\n",
    "\n",
    "class OptimizedImageProcessor:\n",
    "    \"\"\"Optimized image processing for OCR\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_enhanced_versions(image, max_versions=6):\n",
    "        \"\"\"Create limited enhanced versions for OCR\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        versions = []\n",
    "        \n",
    "        # 1. Original resized (3x scale)\n",
    "        resized = cv2.resize(gray, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "        versions.append(resized)\n",
    "        \n",
    "        # 2. CLAHE enhanced and resized\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        clahe_enhanced = clahe.apply(gray)\n",
    "        clahe_resized = cv2.resize(clahe_enhanced, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "        versions.append(clahe_resized)\n",
    "        \n",
    "        # 3. Binary threshold\n",
    "        thresh_val = np.mean(gray) + np.std(gray)\n",
    "        _, binary = cv2.threshold(gray, thresh_val, 255, cv2.THRESH_BINARY)\n",
    "        binary_resized = cv2.resize(binary, None, fx=3, fy=3, interpolation=cv2.INTER_NEAREST)\n",
    "        versions.append(binary_resized)\n",
    "        \n",
    "        # 4. Inverted binary\n",
    "        inverted = cv2.bitwise_not(binary)\n",
    "        inverted_resized = cv2.resize(inverted, None, fx=3, fy=3, interpolation=cv2.INTER_NEAREST)\n",
    "        versions.append(inverted_resized)\n",
    "        \n",
    "        # 5. Adaptive threshold\n",
    "        adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                       cv2.THRESH_BINARY, 11, 2)\n",
    "        adaptive_resized = cv2.resize(adaptive, None, fx=3, fy=3, interpolation=cv2.INTER_NEAREST)\n",
    "        versions.append(adaptive_resized)\n",
    "        \n",
    "        # 6. Edge enhanced\n",
    "        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "        edge_enhanced = cv2.filter2D(gray, -1, kernel)\n",
    "        edge_enhanced = np.clip(edge_enhanced, 0, 255).astype(np.uint8)\n",
    "        edge_resized = cv2.resize(edge_enhanced, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "        versions.append(edge_resized)\n",
    "        \n",
    "        return versions[:max_versions]\n",
    "\n",
    "def optimized_tesseract_ocr(image):\n",
    "    \"\"\"Optimized Tesseract OCR with fewer configurations\"\"\"\n",
    "    configs = [\n",
    "        r'--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789.',\n",
    "        r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789.',\n",
    "        r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789.',\n",
    "        r'--oem 3 --psm 13 -c tessedit_char_whitelist=0123456789.',\n",
    "    ]\n",
    "    \n",
    "    results = set()\n",
    "    \n",
    "    for config in configs:\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(image, config=config).strip()\n",
    "            if text:\n",
    "                # Clean and extract numbers\n",
    "                cleaned = re.sub(r'[^\\d.]', '', text)\n",
    "                if cleaned and len(cleaned) >= 1:\n",
    "                    results.add(cleaned)\n",
    "                \n",
    "                # Extract number patterns\n",
    "                numbers = re.findall(r'\\d+\\.?\\d*', text)\n",
    "                results.update(num for num in numbers if len(num) >= 1)\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Tesseract config failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return list(results)\n",
    "\n",
    "def optimized_easyocr_detection(image):\n",
    "    \"\"\"Optimized EasyOCR with fewer configurations\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    try:\n",
    "        # Single configuration with good balance\n",
    "        ocr_results = reader.readtext(image, detail=1, width_ths=0.5, height_ths=0.7, paragraph=False)\n",
    "        \n",
    "        for bbox, text, conf in ocr_results:\n",
    "            if conf > 0.1:  # Lower threshold to catch more\n",
    "                cleaned = re.sub(r'[^\\d.]', '', text)\n",
    "                if cleaned:\n",
    "                    results.append((cleaned, conf))\n",
    "                \n",
    "                # Also try original text\n",
    "                if text.strip() != cleaned:\n",
    "                    results.append((text.strip(), conf))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"EasyOCR failed: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def format_weight_smart(raw_text):\n",
    "    \"\"\"Smart weight formatting\"\"\"\n",
    "    if not raw_text:\n",
    "        return None\n",
    "    \n",
    "    text = str(raw_text).strip().replace(' ', '').replace('O', '0').replace('o', '0')\n",
    "    \n",
    "    # Remove non-digit characters except decimal point\n",
    "    digits_only = re.sub(r'[^\\d.]', '', text)\n",
    "    if not digits_only or len(digits_only) < 1:\n",
    "        return None\n",
    "    \n",
    "    # Handle multiple decimal points\n",
    "    if digits_only.count('.') > 1:\n",
    "        parts = digits_only.split('.')\n",
    "        digits_only = parts[0] + '.' + ''.join(parts[1:])\n",
    "    \n",
    "    try:\n",
    "        num = float(digits_only)\n",
    "        if 0.001 <= num <= 999999:\n",
    "            return digits_only\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Try adding decimal point for long numbers without decimal\n",
    "    if '.' not in digits_only and len(digits_only) > 3:\n",
    "        for pos in [3, 2, 1]:\n",
    "            if len(digits_only) > pos:\n",
    "                formatted = digits_only[:-pos] + '.' + digits_only[-pos:]\n",
    "                try:\n",
    "                    num = float(formatted)\n",
    "                    if 0.001 <= num <= 999999:\n",
    "                        return formatted\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "def detect_weight_optimized(image_path):\n",
    "    \"\"\"Optimized main detection function\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            logger.error(f\"Could not load image: {image_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading image: {e}\")\n",
    "        return None\n",
    "    \n",
    "    detector = OptimizedDisplayDetector()\n",
    "    processor = OptimizedImageProcessor()\n",
    "    \n",
    "    # Get regions to process\n",
    "    regions_to_process = []\n",
    "    \n",
    "    # Try red/orange detection first\n",
    "    red_result = detector.detect_red_orange_numbers(image)\n",
    "    if red_result[0] is not None:\n",
    "        regions_to_process.append(('red_orange', red_result[1]))\n",
    "        logger.info(\"Red/orange region detected\")\n",
    "    \n",
    "    # Add bright regions as fallback\n",
    "    bright_regions = detector.detect_bright_regions(image)\n",
    "    for i, (x, y, w, h) in enumerate(bright_regions[:2]):  # Limit to 2 regions\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        regions_to_process.append((f'bright_{i}', roi))\n",
    "    \n",
    "    # Fallback to full image if no regions\n",
    "    if not regions_to_process:\n",
    "        regions_to_process.append(('full_image', image))\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for region_name, roi in regions_to_process:\n",
    "        # Create enhanced versions (limited to 4 for speed)\n",
    "        enhanced_versions = processor.create_enhanced_versions(roi, max_versions=4)\n",
    "        \n",
    "        for i, enhanced_img in enumerate(enhanced_versions):\n",
    "            # Run OCR methods\n",
    "            tesseract_results = optimized_tesseract_ocr(enhanced_img)\n",
    "            easyocr_results = optimized_easyocr_detection(enhanced_img)\n",
    "            \n",
    "            # Process results\n",
    "            for result in tesseract_results:\n",
    "                formatted = format_weight_smart(result)\n",
    "                if formatted:\n",
    "                    confidence = 0.8 if 'red_orange' in region_name else 0.6\n",
    "                    all_detections.append((formatted, confidence, f'Tesseract-{region_name}_v{i+1}'))\n",
    "            \n",
    "            for text, conf in easyocr_results:\n",
    "                formatted = format_weight_smart(text)\n",
    "                if formatted:\n",
    "                    if 'red_orange' in region_name:\n",
    "                        conf = min(1.0, conf * 1.2)\n",
    "                    all_detections.append((formatted, conf, f'EasyOCR-{region_name}_v{i+1}'))\n",
    "    \n",
    "    # Get best result\n",
    "    results = {\n",
    "        'image_path': image_path,\n",
    "        'best_detection': 'Not detected',\n",
    "        'confidence': 0,\n",
    "        'method': 'None',\n",
    "        'processing_time': time.time() - start_time,\n",
    "        'total_detections': len(all_detections)\n",
    "    }\n",
    "    \n",
    "    if all_detections:\n",
    "        # Sort by confidence and prefer longer numbers\n",
    "        all_detections.sort(key=lambda x: (x[1], len(x[0])), reverse=True)\n",
    "        \n",
    "        best = all_detections[0]\n",
    "        results['best_detection'] = best[0]\n",
    "        results['confidence'] = best[1]\n",
    "        results['method'] = best[2]\n",
    "        \n",
    "        # Log top detections\n",
    "        logger.info(\"Top detections:\")\n",
    "        for i, (text, conf, method) in enumerate(all_detections[:5]):\n",
    "            logger.info(f\"  {i+1}. {text} (conf: {conf:.2f}, method: {method})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    logger.info(\"Starting optimized digital display weight detection...\")\n",
    "    image_path = r\"Copy of Image_3120.jpg\"\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"❌ Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📷 Processing Image: {image_path}\")\n",
    "    results = detect_weight_optimized(image_path)\n",
    "    \n",
    "    if results:\n",
    "        print(f\"✅ Best Detection: {results['best_detection']}\")\n",
    "        print(f\"🎯 Method: {results['method']}\")\n",
    "        print(f\"📈 Confidence: {results['confidence']:.2f}\")\n",
    "        print(f\"⏱️ Processing Time: {results['processing_time']:.2f} seconds\")\n",
    "        print(f\"🔍 Total Detections: {results['total_detections']}\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to process {image_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ad607",
   "metadata": {},
   "source": [
    "# For Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86574863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import easyocr\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import logging\n",
    "from scipy import ndimage\n",
    "from skimage import restoration, filters, exposure\n",
    "import math\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize EasyOCR\n",
    "reader = easyocr.Reader(['en'], gpu=False)  # Set to True if you have GPU\n",
    "\n",
    "class DigitalDisplayDetector:\n",
    "    \"\"\"Specialized detector for digital displays with multiple color support\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_colored_display_region(image, color_name, hsv_lower, hsv_upper):\n",
    "        \"\"\"Detect specific colored digital display regions\"\"\"\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, hsv_lower, hsv_upper)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            padding = 20\n",
    "            x = max(0, x - padding)\n",
    "            y = max(0, y - padding)\n",
    "            w = min(image.shape[1] - x, w + 2 * padding)\n",
    "            h = min(image.shape[0] - y, h + 2 * padding)\n",
    "            return (x, y, w, h)\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_red_numbers(image):\n",
    "        \"\"\"Detect red numbers with improved contour grouping\"\"\"\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        lower_red1 = np.array([0, 120, 70])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([170, 120, 70])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "        mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "        red_mask = mask1 | mask2\n",
    "\n",
    "        contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if not contours:\n",
    "            return None\n",
    "\n",
    "        # Filter contours\n",
    "        valid_contours = [c for c in contours if 50 < cv2.contourArea(c) < 5000 and \n",
    "                          0.2 < (cv2.boundingRect(c)[2] / cv2.boundingRect(c)[3]) < 5]\n",
    "        if not valid_contours:\n",
    "            return None\n",
    "\n",
    "        # Get bounding boxes and centers\n",
    "        boxes = [cv2.boundingRect(c) for c in valid_contours]\n",
    "        centers = [(x + w/2, y + h/2) for x, y, w, h in boxes]\n",
    "        sorted_indices = sorted(range(len(centers)), key=lambda i: centers[i][0])\n",
    "        sorted_contours = [valid_contours[i] for i in sorted_indices]\n",
    "        sorted_boxes = [boxes[i] for i in sorted_indices]\n",
    "        sorted_centers = [centers[i] for i in sorted_indices]\n",
    "\n",
    "        # Calculate average dimensions\n",
    "        avg_w = np.mean([w for _, _, w, _ in sorted_boxes])\n",
    "        avg_h = np.mean([h for _, _, _, h in sorted_boxes])\n",
    "\n",
    "        # Group contours\n",
    "        groups = []\n",
    "        current_group = [sorted_contours[0]]\n",
    "        for i in range(1, len(sorted_contours)):\n",
    "            dx = sorted_centers[i][0] - sorted_centers[i-1][0]\n",
    "            dy = abs(sorted_centers[i][1] - sorted_centers[i-1][1])\n",
    "            if dx < 1.5 * avg_w and dy < 0.5 * avg_h:\n",
    "                current_group.append(sorted_contours[i])\n",
    "            else:\n",
    "                groups.append(current_group)\n",
    "                current_group = [sorted_contours[i]]\n",
    "        if current_group:\n",
    "            groups.append(current_group)\n",
    "\n",
    "        # Evaluate groups\n",
    "        best_group = None\n",
    "        max_contours = 0\n",
    "        min_y_std = float('inf')\n",
    "        for group in groups:\n",
    "            if len(group) < 2:  # At least 2 contours for a number\n",
    "                continue\n",
    "            x_coords = [min(cv2.boundingRect(c)[0] for c in group)]\n",
    "            y_coords = [min(cv2.boundingRect(c)[1] for c in group)]\n",
    "            w_coords = [max(cv2.boundingRect(c)[0] + cv2.boundingRect(c)[2] for c in group)]\n",
    "            h_coords = [max(cv2.boundingRect(c)[1] + cv2.boundingRect(c)[3] for c in group)]\n",
    "            x, y = min(x_coords), min(y_coords)\n",
    "            w, h = max(w_coords) - x, max(h_coords) - y\n",
    "            aspect_ratio = w / h\n",
    "            y_centers = [cv2.boundingRect(c)[1] + cv2.boundingRect(c)[3]/2 for c in group]\n",
    "            y_std = np.std(y_centers) if len(y_centers) > 1 else 0\n",
    "\n",
    "            if aspect_ratio > 2 and len(group) >= max_contours and y_std < min_y_std:\n",
    "                best_group = (x, y, w, h)\n",
    "                max_contours = len(group)\n",
    "                min_y_std = y_std\n",
    "\n",
    "        if best_group:\n",
    "            x, y, w, h = best_group\n",
    "            padding = 10\n",
    "            x = max(0, x - padding)\n",
    "            y = max(0, y - padding)\n",
    "            w = min(image.shape[1] - x, w + 2 * padding)\n",
    "            h = min(image.shape[0] - y, h + 2 * padding)\n",
    "            return (x, y, w, h)\n",
    "        \n",
    "        # Fallback to largest contour\n",
    "        if valid_contours:\n",
    "            largest = max(valid_contours, key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(largest)\n",
    "            padding = 10\n",
    "            x = max(0, x - padding)\n",
    "            y = max(0, y - padding)\n",
    "            w = min(image.shape[1] - x, w + 2 * padding)\n",
    "            h = min(image.shape[0] - y, h + 2 * padding)\n",
    "            return (x, y, w, h)\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_bright_region(image):\n",
    "        \"\"\"Detect bright regions that might contain digital displays\"\"\"\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if contours:\n",
    "            valid_contours = []\n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                aspect_ratio = w / h if h > 0 else 0\n",
    "                if area > 500 and 2 < aspect_ratio < 8:\n",
    "                    valid_contours.append(contour)\n",
    "            \n",
    "            if valid_contours:\n",
    "                largest_contour = max(valid_contours, key=cv2.contourArea)\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "                padding = 10\n",
    "                x = max(0, x - padding)\n",
    "                y = max(0, y - padding)\n",
    "                w = min(image.shape[1] - x, w + 2 * padding)\n",
    "                h = min(image.shape[0] - y, h + 2 * padding)\n",
    "                return (x, y, w, h)\n",
    "        return None\n",
    "\n",
    "class BlurDetector:\n",
    "    \"\"\"Detect and measure blur in images\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect_blur(image):\n",
    "        \"\"\"Detect blur using multiple methods\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        gray = gray.astype(np.uint8)\n",
    "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2).mean()\n",
    "        blur_score = {\n",
    "            'laplacian_variance': laplacian_var,\n",
    "            'gradient_magnitude': gradient_magnitude,\n",
    "            'is_blurred': laplacian_var < 100 or gradient_magnitude < 10\n",
    "        }\n",
    "        return blur_score\n",
    "\n",
    "class AdvancedDeblurrer:\n",
    "    \"\"\"Advanced deblurring techniques specifically for digital displays\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def safe_image_conversion(image):\n",
    "        \"\"\"Safely convert image to proper format\"\"\"\n",
    "        if isinstance(image, np.ndarray):\n",
    "            if len(image.shape) == 3:\n",
    "                if image.shape[2] == 3:\n",
    "                    return image.astype(np.uint8)\n",
    "            else:\n",
    "                return image.astype(np.uint8)\n",
    "        return np.array(image, dtype=np.uint8)\n",
    "    \n",
    "    @staticmethod\n",
    "    def enhance_for_ocr(image, region_name=None):\n",
    "        \"\"\"Enhance image for OCR based on display type\"\"\"\n",
    "        image = AdvancedDeblurrer.safe_image_conversion(image)\n",
    "        \n",
    "        # Select appropriate channel\n",
    "        if len(image.shape) == 3:\n",
    "            if region_name and 'red' in region_name:\n",
    "                channel = image[:,:,2]  # Red channel\n",
    "            elif region_name and 'green' in region_name:\n",
    "                channel = image[:,:,1]  # Green channel\n",
    "            elif region_name and 'blue' in region_name:\n",
    "                channel = image[:,:,0]  # Blue channel\n",
    "            else:\n",
    "                channel = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            channel = image\n",
    "\n",
    "        enhanced_versions = []\n",
    "        enhanced_versions.append(channel)  # Original channel\n",
    "\n",
    "        # CLAHE\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "        clahe_enhanced = clahe.apply(channel)\n",
    "        enhanced_versions.append(clahe_enhanced)\n",
    "\n",
    "        # Adaptive threshold\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(channel, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                                cv2.THRESH_BINARY, 11, 2)\n",
    "        enhanced_versions.append(adaptive_thresh)\n",
    "\n",
    "        # Unsharp masking\n",
    "        gaussian = cv2.GaussianBlur(channel, (3,3), 0)\n",
    "        unsharp = cv2.addWeighted(channel, 2.0, gaussian, -1.0, 0)  # Stronger sharpening\n",
    "        unsharp = np.clip(unsharp, 0, 255).astype(np.uint8)\n",
    "        enhanced_versions.append(unsharp)\n",
    "\n",
    "        # Binary threshold for bright digits\n",
    "        thresh = 0.8 * np.max(channel)\n",
    "        _, binary = cv2.threshold(channel, thresh, 255, cv2.THRESH_BINARY)\n",
    "        enhanced_versions.append(binary)\n",
    "\n",
    "        # Inverted binary (for OCR flexibility)\n",
    "        inverted_binary = cv2.bitwise_not(binary)\n",
    "        enhanced_versions.append(inverted_binary)\n",
    "\n",
    "        return enhanced_versions\n",
    "\n",
    "def enhanced_tesseract_ocr(image):\n",
    "    \"\"\"Enhanced Tesseract OCR with configurations optimized for digital displays\"\"\"\n",
    "    configs = [\n",
    "        r'--oem 3 --psm 6',\n",
    "        r'--oem 3 --psm 7',\n",
    "        r'--oem 3 --psm 8',\n",
    "        r'--oem 3 --psm 10',\n",
    "        r'--oem 3 --psm 13',\n",
    "        r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789.',\n",
    "        r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789.',\n",
    "        r'--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789.',\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for config in configs:\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(image, config=config).strip()\n",
    "            if text:\n",
    "                cleaned_text = re.sub(r'[^\\d.]', '', text)\n",
    "                if cleaned_text and len(cleaned_text) >= 1:\n",
    "                    results.append(cleaned_text)\n",
    "                numbers = re.findall(r'\\d+\\.?\\d*', text)\n",
    "                for num in numbers:\n",
    "                    if len(num) >= 1:\n",
    "                        results.append(num)\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Tesseract config failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return list(set(results))\n",
    "\n",
    "def enhanced_easyocr_detection(image):\n",
    "    \"\"\"Enhanced EasyOCR with multiple confidence levels\"\"\"\n",
    "    results = []\n",
    "    try:\n",
    "        for confidence_threshold in [0.05, 0.1, 0.2, 0.3, 0.5]:\n",
    "            ocr_results = reader.readtext(image, detail=1, paragraph=False, \n",
    "                                        width_ths=0.5, height_ths=0.7)\n",
    "            for bbox, text, conf in ocr_results:\n",
    "                if conf > confidence_threshold:\n",
    "                    results.append((text.strip(), conf, 'original'))\n",
    "                    cleaned = re.sub(r'[^\\d.]', '', text)\n",
    "                    if cleaned and cleaned != text.strip():\n",
    "                        results.append((cleaned, conf, 'cleaned'))\n",
    "    except Exception as e:\n",
    "        logger.error(f\"EasyOCR failed: {e}\")\n",
    "    return results\n",
    "\n",
    "def format_weight_smart(raw_text):\n",
    "    \"\"\"Smart weight formatting that preserves the actual reading\"\"\"\n",
    "    if not raw_text:\n",
    "        return None\n",
    "    \n",
    "    text = str(raw_text).strip().replace(' ', '').replace('O', '0').replace('o', '0')\n",
    "    if re.match(r'^\\d+\\.?\\d*$', text):\n",
    "        try:\n",
    "            num = float(text)\n",
    "            if 0.001 <= num <= 999999:\n",
    "                return text\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    digits_only = re.sub(r'[^\\d.]', '', text)\n",
    "    if not digits_only or len(digits_only) < 1:\n",
    "        return None\n",
    "    \n",
    "    if digits_only.count('.') > 1:\n",
    "        parts = digits_only.split('.')\n",
    "        digits_only = parts[0] + '.' + ''.join(parts[1:])\n",
    "    \n",
    "    try:\n",
    "        num = float(digits_only)\n",
    "        if 0.001 <= num <= 999999:\n",
    "            return digits_only\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if '.' not in digits_only and len(digits_only) > 3:\n",
    "        test_positions = [3, 2, 1]\n",
    "        for pos in test_positions:\n",
    "            if len(digits_only) > pos:\n",
    "                formatted = digits_only[:-pos] + '.' + digits_only[-pos:]\n",
    "                try:\n",
    "                    num = float(formatted)\n",
    "                    if 0.001 <= num <= 999999:\n",
    "                        return formatted\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    try:\n",
    "        num = float(digits_only)\n",
    "        if 0.001 <= num <= 999999:\n",
    "            return digits_only\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def detect_weight_with_blur_handling(image_path):\n",
    "    \"\"\"Main detection function with improved digital display handling\"\"\"\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            logger.error(f\"Could not load image: {image_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading image: {e}\")\n",
    "        return None\n",
    "    \n",
    "    display_regions = []\n",
    "    green_region = DigitalDisplayDetector.detect_colored_display_region(\n",
    "        image, \"green\", np.array([40, 50, 50]), np.array([80, 255, 255])\n",
    "    )\n",
    "    if green_region:\n",
    "        display_regions.append(('green_display', green_region))\n",
    "    \n",
    "    blue_region = DigitalDisplayDetector.detect_colored_display_region(\n",
    "        image, \"blue\", np.array([90, 50, 50]), np.array([130, 255, 255])\n",
    "    )\n",
    "    if blue_region:\n",
    "        display_regions.append(('blue_display', blue_region))\n",
    "    \n",
    "    white_region = DigitalDisplayDetector.detect_colored_display_region(\n",
    "        image, \"white\", np.array([0, 0, 200]), np.array([180, 30, 255])\n",
    "    )\n",
    "    if white_region:\n",
    "        display_regions.append(('white_display', white_region))\n",
    "    \n",
    "    red_numbers = DigitalDisplayDetector.detect_red_numbers(image)\n",
    "    if red_numbers:\n",
    "        display_regions.append(('red_numbers', red_numbers))\n",
    "    \n",
    "    bright_region = DigitalDisplayDetector.detect_bright_region(image)\n",
    "    if bright_region:\n",
    "        display_regions.append(('bright_display', bright_region))\n",
    "    \n",
    "    if not display_regions:\n",
    "        h, w = image.shape[:2]\n",
    "        display_regions.append(('full_image', (0, 0, w, h)))\n",
    "    \n",
    "    blur_info = BlurDetector.detect_blur(image)\n",
    "    \n",
    "    results = {\n",
    "        'image_path': image_path,\n",
    "        'blur_info': blur_info,\n",
    "        'detections': {},\n",
    "        'best_detection': 'Not detected',\n",
    "        'confidence': 0,\n",
    "        'method': 'None',\n",
    "        'regions_detected': len(display_regions)\n",
    "    }\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for region_name, (x, y, w, h) in display_regions:\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        enhanced_versions = AdvancedDeblurrer.enhance_for_ocr(roi, region_name=region_name)\n",
    "        \n",
    "        for i, enhanced_img in enumerate(enhanced_versions):\n",
    "            method_name = f\"{region_name}_v{i+1}\"\n",
    "            tesseract_results = enhanced_tesseract_ocr(enhanced_img)\n",
    "            easyocr_results = enhanced_easyocr_detection(enhanced_img)\n",
    "            \n",
    "            results['detections'][method_name] = {\n",
    "                'tesseract': tesseract_results,\n",
    "                'easyocr': [(text, conf) for text, conf, _ in easyocr_results]\n",
    "            }\n",
    "            \n",
    "            for result in tesseract_results:\n",
    "                formatted = format_weight_smart(result)\n",
    "                if formatted:\n",
    "                    conf_boost = 0.7 if 'display' in region_name else 0.5\n",
    "                    if region_name == 'red_numbers':\n",
    "                        conf_boost = 0.9\n",
    "                    all_detections.append((formatted, conf_boost, f'Tesseract-{method_name}'))\n",
    "            \n",
    "            for text, conf, text_type in easyocr_results:\n",
    "                formatted = format_weight_smart(text)\n",
    "                if formatted:\n",
    "                    if 'display' in region_name or 'red_numbers' in region_name:\n",
    "                        conf = min(1.0, conf * 1.2)\n",
    "                    all_detections.append((formatted, conf, f'EasyOCR-{method_name}-{text_type}'))\n",
    "    \n",
    "    if all_detections:\n",
    "        all_detections.sort(key=lambda x: (x[1], len(x[0])), reverse=True)\n",
    "        logger.info(\"Top detections:\")\n",
    "        for i, (text, conf, method) in enumerate(all_detections[:5]):\n",
    "            logger.info(f\"  {i+1}. {text} (conf: {conf:.2f}, method: {method})\")\n",
    "        \n",
    "        best = all_detections[0]\n",
    "        results['best_detection'] = best[0]\n",
    "        results['confidence'] = best[1]\n",
    "        results['method'] = best[2]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def save_results_to_csv(results, csv_path=\"enhanced_weight_results.csv\"):\n",
    "    \"\"\"Save results to CSV with detailed information\"\"\"\n",
    "    try:\n",
    "        image_name = os.path.basename(results['image_path'])\n",
    "        new_record = pd.DataFrame({\n",
    "            \"Image_Name\": [image_name],\n",
    "            \"Detected_Weight\": [results['best_detection']],\n",
    "            \"Confidence\": [results['confidence']],\n",
    "            \"Detection_Method\": [results['method']],\n",
    "            \"Is_Blurred\": [results['blur_info']['is_blurred']],\n",
    "            \"Laplacian_Variance\": [results['blur_info']['laplacian_variance']],\n",
    "            \"Gradient_Magnitude\": [results['blur_info']['gradient_magnitude']],\n",
    "            \"Regions_Detected\": [results['regions_detected']]\n",
    "        })\n",
    "        \n",
    "        if os.path.exists(csv_path):\n",
    "            existing_df = pd.read_csv(csv_path)\n",
    "            updated_df = pd.concat([existing_df, new_record], ignore_index=True)\n",
    "            updated_df = updated_df.drop_duplicates(subset=[\"Image_Name\"], keep=\"last\")\n",
    "            updated_df.to_csv(csv_path, index=False)\n",
    "        else:\n",
    "            new_record.to_csv(csv_path, index=False)\n",
    "        logger.info(f\"Results saved to {csv_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save results: {e}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for single image detection\"\"\"\n",
    "    logger.info(\"Starting enhanced digital display weight detection...\")\n",
    "    image_path = r\"Copy of Image_3195.jpg\"\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"❌ Image not found: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n📷 Processing Image: {image_path}\")\n",
    "    results = detect_weight_with_blur_handling(image_path)\n",
    "    \n",
    "    best = results['best_detection']\n",
    "    if best and isinstance(best, str) and '.' not in best and best.isdigit() and len(best) > 3:\n",
    "        best = best[:-3] + '.' + best[-3:]\n",
    "        results['best_detection'] = best\n",
    "    \n",
    "    if results:\n",
    "        blur_status = \"🌫️ BLURRED\" if results['blur_info']['is_blurred'] else \"✨ CLEAR\"\n",
    "        print(f\"🔍 Image Quality: {blur_status}\")\n",
    "        print(f\"📊 Blur Metrics:\")\n",
    "        print(f\"   - Laplacian Variance: {results['blur_info']['laplacian_variance']:.2f}\")\n",
    "        print(f\"   - Gradient Magnitude: {results['blur_info']['gradient_magnitude']:.2f}\")\n",
    "        print(f\"🎯 Regions Found: {results['regions_detected']}\")\n",
    "        print(f\"✅ Best Detection: {results['best_detection']}\")\n",
    "        print(f\"🎯 Method: {results['method']}\")\n",
    "        print(f\"📈 Confidence: {results['confidence']:.2f}\")\n",
    "        save_results_to_csv(results)\n",
    "        print(f\"💾 Results saved to enhanced_weight_results.csv\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to process {image_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
